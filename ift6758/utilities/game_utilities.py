import os
from os.path import dirname, abspath

import numpy as np
import orjson
import pandas as pd

from ift6758.api.nhl_api_service import get_game_live_feed


def get_game_data(game_id: str, save_to_json: bool = True) -> dict:
    """
    Get the game data from local JSON file if exists, or calls NHL API to retrieve it if it does not
    A game ID is composed of the following parts:
        First 4 digits: Start year of season
        Next 2 digits: Type of game (01 = preseason, 02 = regular season, 03 = playoffs, 04 = all-star)
        Next 4 digits: Game number

    Files are organized in the following directory: game_data/{Start year of season}/{Type of game}/{Game number}.json

    Args:
        game_id: Game ID
        save_to_json: True for saving game data in .json file for easier retrieval, False otherwise

    Returns:
        Live feed of game as a dict
    """
    directory = f'data/game_data/{game_id[0:4]}/{game_id[4:6]}'
    directory_path = os.path.join(dirname(dirname(abspath(__file__))), directory)
    file_name = f'{game_id[6:10]}.json'
    file_path = os.path.join(directory_path, file_name)

    if not os.path.exists(directory_path):
        os.makedirs(directory_path)

    if os.path.exists(file_path):
        with open(file_path, "rb") as f:
            live_feed = orjson.loads(f.read())
    else:
        live_feed = get_game_live_feed(game_id)
        if save_to_json:
            with open(file_path, 'wb') as fp:
                fp.write(orjson.dumps(live_feed))

    return live_feed


def plays_to_frame(live_data: dict) -> pd.DataFrame:
    """
    Transform all plays from live data from JSON to a data frame, with extra columns representing the game ID, season and type of game (preseason, regular, playoff or all-star)

    Args:
        live_data: Game live data as a dict

    Returns:
        Data frame representation of game data
    """

    df = pd.json_normalize(live_data['liveData']['plays']['allPlays'])

    # Add game metadata
    df['gameId'] = live_data['gamePk']
    df['season'] = live_data['gameData']['game']['season']
    df['gameType'] = live_data['gameData']['game']['type']

    # Assign team types
    df.loc[df['team.id'] == live_data['gameData']['teams']['home']['id'], 'teamType'] = 'home'
    df.loc[df['team.id'] == live_data['gameData']['teams']['away']['id'], 'teamType'] = 'away'

    # Join with period information to get the rink side
    df = df.merge(pd.json_normalize(live_data['liveData']['linescore']['periods']), left_on='about.period',
                  right_on='num')

    return df


def extract_players(plays_df: pd.DataFrame) -> pd.DataFrame:
    """
    Extract players into columns by player type and add them to the data frame representing live, play-by-play data
    Since each play type has a different set of player types, this process is done one play type at a time

    Args:
        plays_df: Data frame representing plays generated by plays_to_frame

    Returns:
        Data frame with additional columns for each type of player implied in the play, replacing the 'players' column,
        in increasing dateTime order
    """

    distinct_play_types = set(plays_df['event'])

    combined_plays_df = pd.concat([_extract_players_for_type(plays_df[plays_df['event'] == play_type])
                                   for play_type in distinct_play_types], ignore_index=True)

    # Sort combined play data in increasing dateTime order
    # As players have been extracted, there is no need to keep the column 'players'
    return combined_plays_df.sort_values(by='dateTime', kind='mergesort').drop(columns=['players']).reset_index(drop=True)


def _extract_players_for_type(plays_df: pd.DataFrame) -> pd.DataFrame:
    """
    Extract players into columns by player type and add them to the data frame representing live, play-by-play data

    Args:
        plays_df: Data frame containing all play-by-play data for one specific type

    Returns:
        Data frame with additional columns for each type of player implied in the play
    """

    if len(plays_df['event'].unique()) != 1:
        raise ValueError('Play data may only contain one type of play at a time!')

    if plays_df['players'].isna().any():
        # If no players for this type of play, do not do anything
        return plays_df
    else:
        # Here, assume the first row will always have data for players, given that the input data frame only contains one type of play
        distinct_player_types = set([player['playerType'] for player in plays_df['players'].iloc[0]])

        # Extract players series into columns of players' names
        players_df = plays_df['players'].apply(_extract_player_full_names, args=(distinct_player_types,))

        # When there are no players in a category, they are denoted with an empty string, replace them with nan instead
        players_df.replace('', np.nan, inplace=True)

        # Columns in players_df are in the order of distinct_player_types
        players_df.columns = [x.lower() for x in distinct_player_types]

        # Left join on plays_df
        return plays_df.merge(players_df, left_index=True, right_index=True)


def _extract_player_full_names(players: list, distinct_player_types: set) -> pd.Series:
    """
    Extract players' full names into a series of names in which each entry is a list of players joined by ', ' of each
    specific type in distinct_player_types

    Args:
        players: List of players
        distinct_player_types: Set of distinct player types

    Returns:
        Series of players' full names in the order of distinct_player_types
    """

    return pd.Series(
        [', '.join([player['player']['fullName'] for player in players if player['playerType'] in player_type]) for
         player_type in distinct_player_types])
